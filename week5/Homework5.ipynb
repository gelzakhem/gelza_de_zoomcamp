{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d4d82f-ab08-4075-9720-f80bcac8fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39afa818-4eed-4a1c-b9d3-540dd444f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/04 20:14:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598328e-e0f5-4e16-abce-b8ae2f0f73be",
   "metadata": {},
   "source": [
    "# Question 1 Pyspark Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcbc186f-3b54-4d5d-bad2-774c0b1aea90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f9091-c651-4c4e-9099-b852e1d31389",
   "metadata": {},
   "source": [
    "# Question 2 Repartitioning into Parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b33cc5-7535-4632-be83-a47096b6a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-04 20:24:21--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T202421Z&X-Amz-Expires=300&X-Amz-Signature=fa70f0f7f22370dac8a595bd132df5245001dd84e6bb9d21be032cf77e317f5f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-04 20:24:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T202421Z&X-Amz-Expires=300&X-Amz-Signature=fa70f0f7f22370dac8a595bd132df5245001dd84e6bb9d21be032cf77e317f5f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  31.5MB/s    in 0.6s    \n",
      "\n",
      "2024-03-04 20:24:22 (31.5 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3179055-d6f3-4c9e-96d7-024bd34f6ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fhv_2019_10 = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").csv('fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e8730e-65aa-4f43-ba73-ad74aa56b25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fhv_2019_10.repartition(6).write.parquet('data/pq/fhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3190a85-b516-4765-97d8-1a208fe59efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average size of the parquet files is 6.35 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = 'data/pq/fhv/2019/10/'\n",
    "size = 0\n",
    "count = 0\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('parquet'):\n",
    "        filepath = os.path.join(directory,filename)\n",
    "        size += os.path.getsize(filepath)\n",
    "        count+=1\n",
    "avg_size_mb = (size/count/1024**2)\n",
    "print(f'The average size of the parquet files is {round(avg_size_mb,2)} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeacf382-ebb9-426a-8204-b277537a1681",
   "metadata": {},
   "source": [
    "# Question 3 Longest trip on the 15th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c437259-e329-4997-9d73-1bbfb05ea085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "target_date = '2019-10-15'\n",
    "df_fhv_2019_10.select('pickup_datetime').filter(to_date(df_fhv_2019_10.pickup_datetime) == target_date).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d8495-c296-4df3-98e0-75fcc3e6dd33",
   "metadata": {},
   "source": [
    "# Question 4 Length of the longest trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccb80db3-9df1-4408-b2ad-2adf77d0bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e57fc220-21ac-4d78-8b30-0dfa0c02fc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------------+\n",
      "|pickup_datetime    |dropOff_datetime   |duration_hours    |\n",
      "+-------------------+-------------------+------------------+\n",
      "|2019-10-11 18:00:00|2091-10-11 18:30:00|631152.5          |\n",
      "|2019-10-28 09:00:00|2091-10-28 09:30:00|631152.5          |\n",
      "|2019-10-31 23:46:33|2029-11-01 00:13:00|87672.44083333334 |\n",
      "|2019-10-01 21:43:42|2027-10-01 21:45:23|70128.02805555557 |\n",
      "|2019-10-17 14:00:00|2020-10-18 00:00:00|8794.0            |\n",
      "|2019-10-26 21:26:00|2020-10-26 21:36:00|8784.166666666666 |\n",
      "|2019-10-30 12:30:04|2019-12-30 13:02:08|1464.5344444444445|\n",
      "|2019-10-25 07:04:57|2019-12-08 07:54:33|1056.8266666666666|\n",
      "|2019-10-25 07:04:57|2019-12-08 07:21:11|1056.2705555555556|\n",
      "|2019-10-01 13:47:17|2019-11-03 15:20:28|793.5530555555556 |\n",
      "|2019-10-01 07:21:12|2019-11-03 08:44:21|793.3858333333334 |\n",
      "|2019-10-01 13:41:00|2019-11-03 14:58:51|793.2975          |\n",
      "|2019-10-01 18:43:20|2019-11-03 19:43:13|792.9980555555555 |\n",
      "|2019-10-01 18:43:46|2019-11-03 19:43:04|792.9883333333333 |\n",
      "|2019-10-01 07:07:09|2019-11-03 07:58:46|792.8602777777778 |\n",
      "|2019-10-01 14:49:28|2019-11-03 15:38:07|792.8108333333333 |\n",
      "|2019-10-01 05:36:30|2019-11-03 06:23:36|792.785           |\n",
      "|2019-10-01 15:02:55|2019-11-03 15:49:05|792.7694444444444 |\n",
      "|2019-10-01 06:08:01|2019-11-03 06:53:15|792.7538888888888 |\n",
      "|2019-10-01 06:41:17|2019-11-03 07:26:04|792.7463888888889 |\n",
      "+-------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_duration = df_fhv_2019_10.select(\n",
    "    df_fhv_2019_10.pickup_datetime,\n",
    "    df_fhv_2019_10.dropOff_datetime,\n",
    "    ((unix_timestamp(df_fhv_2019_10.dropOff_datetime) - unix_timestamp(df_fhv_2019_10.pickup_datetime)) / 60/60).alias('duration_hours')\n",
    ")\n",
    "df_with_duration.orderBy(df_with_duration.duration_hours.desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9a362-925d-4e3b-9085-25b55941a905",
   "metadata": {},
   "source": [
    "# Question 5 What Port does spark run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47b85f33-ea81-413c-b68b-78a843852600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI is running on port: 4040\n"
     ]
    }
   ],
   "source": [
    "spark_ui_port = spark.sparkContext.uiWebUrl.split(':')[-1]\n",
    "print(f\"Spark UI is running on port: {spark_ui_port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab090ce6-9cb9-4bf6-bde5-294880e82271",
   "metadata": {},
   "source": [
    "# Question 6 Least Frequent Pickup Location zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6c5521d-e0c0-4026-92b1-af9c829f035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67c874e9-cc7c-40a5-8099-8ae5c5809c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join =df_fhv_2019_10.join(df_zones,df_fhv_2019_10.PUlocationID == df_zones.LocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d25e9b05-8ed3-4b2c-a301-c80f027cefa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Zone|count|\n",
      "+--------------------+-----+\n",
      "|         Jamaica Bay|    1|\n",
      "|Governor's Island...|    2|\n",
      "| Green-Wood Cemetery|    5|\n",
      "|       Broad Channel|    8|\n",
      "|     Highbridge Park|   14|\n",
      "|        Battery Park|   15|\n",
      "|Saint Michaels Ce...|   23|\n",
      "|Breezy Point/Fort...|   25|\n",
      "|Marine Park/Floyd...|   26|\n",
      "|        Astoria Park|   29|\n",
      "|    Inwood Hill Park|   39|\n",
      "|       Willets Point|   47|\n",
      "|Forest Park/Highl...|   53|\n",
      "|  Brooklyn Navy Yard|   57|\n",
      "|        Crotona Park|   62|\n",
      "|        Country Club|   77|\n",
      "|     Freshkills Park|   89|\n",
      "|       Prospect Park|   98|\n",
      "|     Columbia Street|  105|\n",
      "|  South Williamsburg|  110|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.groupBy(df_join.Zone).count().alias('total_count').orderBy(\"count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1373a5-d9df-400f-bd58-ca0cf6e44b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
